# -*- coding: utf-8 -*-
"""Rectified Train Project REDD.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1jaYYQEpsQkD6tTvzRJLdqraTMhIpambq

# Set Up Google Drive and fetch Repo
https://medium.com/analytics-vidhya/how-to-use-google-colab-with-github-via-google-drive-68efb23a42d
"""

# # # Ayush
# from google.colab import drive
# drive.mount('/content/drive')
# %cd /content/drive/MyDrive/Project/REDD/projectRedd

# # # # Vibhor
# # # %pip install pynvml
# from google.colab import drive
# drive.mount('/content/drive')
# %cd /content/drive/MyDrive/EECS571/REDD/projectRedd
# model_path = "/content/drive/MyDrive/EECS571/REDD/projectRedd/pre_trained_PSPNet/pspnet_chestxray_best_model_4.pkl"

# Commented out IPython magic to ensure Python compatibility.
# # # Vibhor
# # %pip install pynvml
from google.colab import drive
drive.mount('/content/drive')
# %cd /content/drive/MyDrive/REDD/projectRedd

# Commented out IPython magic to ensure Python compatibility.
# # # Namho
# # %pip install pynvml
from google.colab import drive
drive.mount('/content/drive')
# %cd /content/drive/MyDrive/projectRedd/
model_path = "/content/drive/MyDrive/projectRedd/pre_trained_PSPNet/pspnet_chestxray_best_model_4.pkl"

# #Github Token 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
# username = "ayushsaklani"
# repository = "projectRedd"
# git_token = "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"

# !git clone https://{git_token}@github.com/{username}/{repository}

# %cd projectRedd/

# !wget http://resource.deepwise.com/ChestX-Det/pspnet_chestxray_best_model_4.pkl

"""# Imports

"""

# Commented out IPython magic to ensure Python compatibility.
import json
# %matplotlib inline
# %config InlineBackend.figure_format = 'retina'
from __future__ import print_function
#%matplotlib inline
import argparse
import os
import random

import torch
import torch.nn as nn
import torch.nn.parallel
import torch.backends.cudnn as cudnn
import torch.optim as optim
import torch.utils.data
from torch.utils.data import DataLoader
import torchvision.datasets as dset
import torchvision.transforms as transforms
import torchvision.utils as vutils
from torchvision.transforms.functional import crop
import torchvision.transforms.functional as F
from torchvision.transforms import v2
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.animation as animation
from torchvision import tv_tensors
from torchvision.io import read_image

from PIL import Image,ImageDraw
from torch.utils.data import Dataset
from pathlib import Path

from itertools import chain
import cv2
from skimage import io, transform
from tqdm import tqdm

from pre_trained_PSPNet.ptsemseg.pspnet import pspnet

from torch.utils.data.sampler import SubsetRandomSampler

import warnings
warnings.filterwarnings("ignore", category=DeprecationWarning)

device= torch.device("cuda" if torch.cuda.is_available() else "cpu")

from collections import OrderedDict
def convert_state_dict(state_dict):
    """Converts a state dict saved from a dataParallel module to normal
       module state_dict inplace
       :param state_dict is the loaded DataParallel model_state

    """
    new_state_dict = OrderedDict()
    for k, v in state_dict.items():
        name = k[7:]  # remove `module.`
        new_state_dict[name] = v
    return new_state_dict



"""# Visualize Data"""

def get_disease_color_map():
    disease_color_map = {
    'Atelectasis': (1,(255, 0, 0)),         # Red
    'Calcification': (2,(0, 255, 0)),       # Green
    'Cardiomegaly': (3,(0, 0, 255)),        # Blue
    'Consolidation': (4,(255, 255, 0)),     # Yellow
    'Diffuse Nodule': (5,(255, 0, 255)),    # Magenta
    'Effusion': (6,(0, 255, 255)),          # Cyan
    'Emphysema': (7,(128, 0, 0)),           # Dark Red
    'Fibrosis': (8,(0, 128, 0)),            # Dark Green
    'Fracture': (9,(0, 0, 128)),            # Dark Blue
    'Mass': (10,(128, 128, 0)),              # Olive
    'Nodule': (11,(128, 0, 128)),            # Purple
    'Pleural Thickening': (12,(0, 128, 128)), # Teal
    'Pneumothorax': (13,(128, 128, 128))     # Gray
    }
    return disease_color_map

# Function to create masks of different colors for each disease category
def create_channel_masks(image_shape, polygons, syms):
    #colors = [(255, 0, 0), (0, 255, 0), (0, 0, 255), (255, 255, 0), (255, 0, 255), (0, 255, 255),
              #(128, 0, 0), (0, 128, 0), (0, 0, 128), (128, 128, 0), (128, 0, 128), (0, 128, 128),
              #(255, 128, 0)]  # 13 distinct colors for 13 disease categories
    disease_color_map = get_disease_color_map()
    mask = np.full(image_shape,0)

    for idx, (polygon, sym) in enumerate(zip(polygons, syms)):
      ch = disease_color_map[sym][0] - 1
      mask[:,:,ch] = mask[:,:,ch] | get_mask(polygon)

    return mask

def get_mask(points):
    mask = np.full((1024,1024),False)
    if len(points) ==0:
        return mask
    img = Image.new('L', (1024,1024), 0)
    poly = [(x,y) for x,y in points]
    ImageDraw.Draw(img).polygon(poly, outline=1, fill=1)
    curr_mask = np.array(img)

    return curr_mask

# def load_image(path:str):
#     image = Image.open(path)
#     if image.mode !='RGB' or image.mode != 'RGBA': # converts grayscale image to RGB
#         image = image.convert("RGB")
#     return image

# train_json_path = 'reformatted_ChestX_Det_train.json'
# with open(train_json_path,'r')as f:
#     train_json =  json.load(f)

# train_json['36206.png']

# tfs = list(train_json.keys())
# tfs[1]

# img = load_image(f'train_data/36206.png')
# # plt.imshow(img)
# img

# mask = create_channel_masks((1024,1024,13),train_json['36206.png']["polygons"],train_json['36206.png']["syms"])

# plt.imshow(mask[:,:,2],cmap='gray')

# plt.imshow(mask[:,:,3],cmap='gray')

# from torchvision import tv_tensors
# train_transforms = v2.Compose([
#         v2.Resize(256),
#         # v2.RandomResizedCrop(256),
#         v2.ToTensor()
#         ])

# masks = [tv_tensors.Mask(mask[:,:,ch],dtype = torch.uint8) for ch in range(13)]

# img = [tv_tensors.Image(img,dtype=torch.float)]

# img = train_transforms(mask)

# img,masks = train_transforms(img,masks)

# masks = torch.stack(masks,0)

# masks[2,:,:].unique()

"""# DataLoader

"""

from torch.utils.data import Dataset

def load_image(path:str):
    image = Image.open(path)
    if image.mode !='RGB' or image.mode != 'RGBA': # converts grayscale image to RGB
        image = image.convert("RGB")
    return image

class ImageDataset(Dataset):
    def __init__(self,img_folder:str,transforms_ ,transforms_n,image_size:int,annotation_json,num_classes=13):

        self.folder = img_folder
        self.files = list(annotation_json.keys())
        self.transform = transforms_
        self.transform_n = transform_n
        self.image_size = image_size
        self.annotation_json = annotation_json
        self.nclasses = num_classes

    def __getitem__(self,index):

        img = load_image(os.path.join(self.folder,self.files[index]))
        mask = create_channel_masks((1024,1024,13),self.annotation_json[self.files[index]]["polygons"],self.annotation_json[self.files[index]]["syms"])
        # img = tv_tensors.Image(img,dtype=torch.float32)
        masks = [tv_tensors.Mask(mask[:,:,ch],dtype = torch.uint8) for ch in range(self.nclasses)]

        img, masks = self.transform(img,masks)

        return self.transform_n(img),torch.stack(masks,0)
        return img,torch.stack(masks,0)

    def __len__(self):
        return len(self.files)

from torchvision.transforms.autoaugment import InterpolationMode


train_transforms = v2.Compose([
        v2.Resize(256),
        v2.RandomRotation(5),
        # v2.RandomResizedCrop(256),
        v2.ToTensor()
        ])
transform_n = v2.Compose([v2.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])

IMG_MEAN = [0.485, 0.456, 0.406]
IMG_STD = [0.229, 0.224, 0.225]

def denormalize(x, mean=IMG_MEAN, std=IMG_STD):
    # 3, H, W
    ten = x.clone()
    for t, m, s in zip(ten, mean, std):
        t.mul_(s).add_(m)
    # B, 3, H, W
    return torch.clamp(ten, 0, 1)

def show(imgs):
    if not isinstance(imgs, list):
        imgs = denormalize(imgs)
        imgs = [imgs]

    fig, axs = plt.subplots(ncols=len(imgs), squeeze=False,figsize=(15, 10))
    for i, img in enumerate(imgs):
        img = img.detach()
        img = F.to_pil_image(img)
        axs[0, i].imshow(np.asarray(img))
        axs[0, i].set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])

"""# Custom loss function"""

# def DICE(targets, predictions, num_classes):

#   intersections = torch.zeros(num_classes, device=device)
#   unions = torch.zeros_like(intersections)
#   counts = torch.zeros_like(intersections)
#   # TODO: Discard ignored points
#   # valid_mask = list(range(num_classes)).remove(ignore_index)

#   # Loop over classes and update the counts, unions, and intersections
#   for c in range(num_classes):
#     # TODO: Fill in computation
#     # Add small value to avoid division by 0
#     # Make sure to keep the small smoothing constant to match the autograder

#     unions[c] = torch.sum((targets[c])).float() +torch.sum((predictions[c]) ).float() + 0.00001
#     intersections[c] = torch.sum((targets[c])*(predictions[c]) ).float() + 0.00001
#     counts[c] = torch.sum(targets[c] == 1).float()

#   # Per-class IoU
#   # Make sure to set iou for classes with no points to 1
#   iou = 2*intersections/unions
#   iou[counts == 0.0] =1
#   # Calculate mean, ignoring ignore index
#   miou = torch.mean(iou)

#   return iou, miou

def DICE(target,input,smooth):
    """
    input is a torch variable of size BatchxnclassesxHxW representing log probabilities for each class
    target is a 1-hot representation of the groundtruth, shoud have same size as the input
    """
    assert input.size() == target.size(), "Input sizes must be equal."
    assert input.dim() == 4, "Input must be a 4D Tensor."
    # uniques=np.unique(target.numpy())
    # assert set(list(uniques))<=set([0,1]), "target must only contain zeros and ones"

    probs=torch.sigmoid(input)
    num=probs*target#b,c,h,w--p*g
    num=torch.sum(num,dim=3)#b,c,h
    num=torch.sum(num,dim=2)


    den1=probs*probs#--p^2
    den1=torch.sum(den1,dim=3)#b,c,h
    den1=torch.sum(den1,dim=2)


    den2=target*target#--g^2
    den2=torch.sum(den2,dim=3)#b,c,h
    den2=torch.sum(den2,dim=2)#b,c


    dice=2*((num+smooth)/(den1+den2 + smooth))
    dice_eso=dice#we ignore bg dice val, and take the fg

    dice_total=torch.sum(dice_eso)/dice_eso.size(0)#divide by batch_sz

    return dice_total





"""# Training

"""

train_json_path = 'reformatted_ChestX_Det_train.json'
with open(train_json_path,'r')as f:
    train_json =  json.load(f)

train_path = 'train_data'

dataset = ImageDataset(img_folder=train_path,transforms_=train_transforms,transforms_n = transform_n,image_size = 512,annotation_json = train_json,num_classes =13)
batch_size = 16
validation_split = .1
shuffle_dataset = True
random_seed= 42

dataset_size = len(dataset)
indices = list(range(dataset_size))
split = int(np.floor(validation_split * dataset_size))
if shuffle_dataset :
    np.random.seed(random_seed)
    np.random.shuffle(indices)
train_indices, val_indices = indices[split:], indices[:split]

# Creating PT data samplers and loaders:
train_sampler = SubsetRandomSampler(train_indices)
valid_sampler = SubsetRandomSampler(val_indices)

dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, drop_last=True,sampler = train_sampler)
val_loder = torch.utils.data.DataLoader(dataset, batch_size=1,drop_last=True,sampler = valid_sampler)

images, data = next(iter(dataloader))

grid = vutils.make_grid(images,nrow =batch_size//2)
show(grid)

n_classes = len(get_disease_color_map())

psp_model = pspnet(n_classes)

state = torch.load("models_weights/PSPNet_initial.pth",map_location=device)
psp_model.load_state_dict(state)

for i,param in enumerate(psp_model.named_parameters()):
    if i<318:
        param[1].requires_grad = False
    print(str(i),"    ",param[0], "------",param[1].requires_grad)

def train(daltaloader,val_dataloader,epochs,start_lr):
    os.makedirs("models_weights", exist_ok=True)
    optimizer = optim.Adam(psp_model.parameters(), lr=start_lr)
    psp_model.to(device)
    seg_criterion = nn.BCEWithLogitsLoss()
    avg_loss = []
    avg_vloss = []

    best_val_dice =0
    epoch_losses = {"train":list(),"val":list(),'tdice':list(),'vdice':list()}
    for epoch in range(epochs):
        train_bar = tqdm(dataloader)
        psp_model.train()
        total_loss = 0
        total_dice = 0
        for i,batch in enumerate(train_bar):
            train_bar.set_description("Training")
            data_x,data_y = batch[0].to(device,dtype=torch.float),batch[1].to(device,dtype=torch.float)
            optimizer.zero_grad()
            aux_loss ,out = psp_model(data_x)

            tloss = seg_criterion(out,data_y)
            # out = out.permute(1,0,2,3)
            # data_y = data_y.permute(1,0,2,3)
            dmean= DICE(data_y,out,1e-5)
            loss = tloss + 0.5*(1-dmean)
            loss.backward()
            optimizer.step()
            epoch_losses['train'].append(loss.item())
            epoch_losses['tdice'].append(dmean.item())
            total_loss += loss.item()
            total_dice += dmean.item()

            train_bar.set_postfix_str(f'curr_loss :{loss.item():.3f} dice :{dmean.item():.3f} avg_loss :{total_loss/(i+1):.4f} avg_dice :{total_dice/(i+1):.4f}')
            if i%5 ==0:
             torch.save(psp_model.state_dict(),os.path.join("models_weights", '_'.join(["PSPNet_WOW_UPdated", str(epoch + 1)])))
        #validation part
        val_bar = tqdm(val_dataloader)
        psp_model.eval()
        with torch.no_grad():
            all_targets = []
            all_preds= []
            val_loss = 0
            for i,batch in enumerate(val_bar):
              val_bar.set_description("Validation")
              val_x,val_y = batch[0].to(device,dtype=torch.float),batch[1].to(device,dtype=torch.float)
              vout = psp_model(val_x)
              vloss= seg_criterion(val_y,vout)
              # val_y = val_y.permute(1,0,2,3) #B,C,H,W -> C,B,H,W
              # vout = vout.permute(1,0,2,3)
              all_targets.append(val_y)
              all_preds.append(vout)
              vdmean= DICE(val_y,vout,1e-5)
              vloss = vloss.item() + 0.5*(1-vdmean).item()
              val_loss+=vloss

              epoch_losses['val'].append(vloss)
            all_targets = torch.cat(all_targets,axis=0)
            all_preds = torch.cat(all_preds,axis =0)

            vdmean = DICE(all_targets,all_preds,1e-5)
            val_bar.set_postfix_str(f'loss: {val_loss/(i+1):.4f} dice: {vdmean.item():.4f}')
            print(f'Val DICE : {vdmean.item():.4f}')
            epoch_losses['vdice'].append(vdmean.item())

            if vdmean.item() >best_val_dice:
              best_val_dice = vdmean.item()
              torch.save(psp_model.state_dict(),os.path.join("models_weights", '_'.join(["PSPNet_WOW_UPdated","best_val"])))
              print("saved Best Model")


    return epoch_losses

def train(daltaloader,val_dataloader,epochs,start_lr):
    os.makedirs("models_weights", exist_ok=True)
    optimizer = optim.Adam(psp_model.parameters(), lr=start_lr)
    psp_model.to(device)
    seg_criterion = nn.BCEWithLogitsLoss()
    avg_loss = []
    avg_vloss = []

    best_val_dice =0
    epoch_losses = {"train":list(),"val":list(),'tdice':list(),'vdice':list()}
    for epoch in range(epochs):
        train_bar = tqdm(dataloader)
        psp_model.train()
        total_loss = 0
        total_dice = 0
        for i,batch in enumerate(train_bar):
            train_bar.set_description("Training")
            data_x,data_y = batch[0].to(device,dtype=torch.float),batch[1].to(device,dtype=torch.float)
            optimizer.zero_grad()
            aux_loss ,out = psp_model(data_x)

            tloss = seg_criterion(out,data_y)
            # out = out.permute(1,0,2,3)
            # data_y = data_y.permute(1,0,2,3)
            dmean= DICE(data_y,out,1e-5)
            loss = tloss + 0.5*(1-dmean)
            loss.backward()
            optimizer.step()
            epoch_losses['train'].append(loss.item())
            epoch_losses['tdice'].append(dmean.item())
            total_loss += loss.item()
            total_dice += dmean.item()

            train_bar.set_postfix_str(f'curr_loss :{loss.item():.3f} dice :{dmean.item():.3f} avg_loss :{total_loss/(i+1):.4f} avg_dice :{total_dice/(i+1):.4f}')
            if i%5 ==0:
             torch.save(psp_model.state_dict(),os.path.join("models_weights", '_'.join(["PSPNet_WOW_UPdated_A100", str(epoch + 1)])))
        #validation part
        val_bar = tqdm(val_dataloader)
        psp_model.eval()
        with torch.no_grad():
            all_targets = []
            all_preds= []
            val_loss = 0
            for i,batch in enumerate(val_bar):
              val_bar.set_description("Validation")
              val_x,val_y = batch[0].to(device,dtype=torch.float),batch[1].to(device,dtype=torch.float)
              vout = psp_model(val_x)
              vloss= seg_criterion(val_y,vout)
              # val_y = val_y.permute(1,0,2,3) #B,C,H,W -> C,B,H,W
              # vout = vout.permute(1,0,2,3)
              all_targets.append(val_y)
              all_preds.append(vout)
              vdmean= DICE(val_y,vout,1e-5)
              vloss = vloss.item() + 0.5*(1-vdmean).item()
              val_loss+=vloss

              epoch_losses['val'].append(vloss)
            all_targets = torch.cat(all_targets,axis=0)
            all_preds = torch.cat(all_preds,axis =0)

            vdmean = DICE(all_targets,all_preds,1e-5)
            val_bar.set_postfix_str(f'loss: {val_loss/(i+1):.4f} dice: {vdmean.item():.4f}')
            print(f'Val DICE : {vdmean.item():.4f}')
            epoch_losses['vdice'].append(vdmean.item())

            if vdmean.item() >best_val_dice:
              best_val_dice = vdmean.item()
              torch.save(psp_model.state_dict(),os.path.join("models_weights", '_'.join(["PSPNet_WOW_UPdated_A100","best_val"])))
              print("saved Best Model")


    return epoch_losses

epoch_losses = train(dataloader,val_loder,5,start_lr = 1e-4)

"""# Test"""

# Testing with ground truth
test_json_path = 'reformatted_ChestX_Det_test.json'
with open(test_json_path,'r')as f:
    test_json =  json.load(f)

test_path = 'test_data'
test_dataset = ImageDataset(img_folder=test_path,transforms_=train_transforms,transforms_n = transform_n,image_size = 512,annotation_json = test_json,num_classes =13)
batch_size = 1
random_seed= 42
test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False)

test_json.keys()

test_json["39414.png"]

images,data = next(iter(test_dataloader))

grid = vutils.make_grid(images,nrow =batch_size//2)
show(grid)

vout = psp_model(images.to(device,dtype=torch.float))

vout[vout>=0.5] =1
vout[vout<0.5] =0

vout.unique()

n_classes = len(get_disease_color_map())

psp_model = pspnet(n_classes)

state = torch.load(os.path.join("models_weights", '_'.join(["PSPNet_WOW_UPdated_A100","best_val"])),map_location=device)
psp_model.load_state_dict(state)
psp_model.eval()
psp_model.to(device)

epoch_losses = {'vdice':list()}
test_bar = tqdm(test_dataloader)
seg_criterion = nn.BCEWithLogitsLoss()
psp_model.eval()
v_dice=[]
with torch.no_grad():
    all_targets = []
    all_preds= []
    val_loss = 0
    for i,batch in enumerate(test_bar):
      test_bar.set_description("Validation")
      val_x,val_y = batch[0].to(device,dtype=torch.float),batch[1].to(device,dtype=torch.float)
      vout = psp_model(val_x)
      vloss= seg_criterion(val_y,vout)
      # val_y = val_y.permute(1,0,2,3) #B,C,H,W -> C,B,H,W
      # vout = vout.permute(1,0,2,3)
      all_targets.append(val_y)
      all_preds.append(vout)
      vdmean= DICE(val_y,vout,1e-5)
      vloss = vloss.item() + 0.5*(1-vdmean).item()
      val_loss+=vloss
      v_dice.append(vdmean.item())
      test_bar.set_postfix_str(f'loss: {val_loss/(i+1):.4f} dice: {vdmean.item():.4f}')
    all_targets = torch.cat(all_targets,axis=0)
    all_preds = torch.cat(all_preds,axis =0)

    vdmean = DICE(all_targets,all_preds,1e-5)

    print(f'Test DICE : {vdmean.item():.4f}')
    epoch_losses['vdice'].append(vdmean.item())

"""# [DBG] Model Size"""

model = psp_model
param_size = 0
for param in model.parameters():
    param_size += param.nelement() * param.element_size()
buffer_size = 0
for buffer in model.buffers():
    buffer_size += buffer.nelement() * buffer.element_size()

size_all_mb = (param_size + buffer_size) / 1024**2
print('model size: {:.3f}MB'.format(size_all_mb))

torch.cuda.memory_summary(device)

"""# Quantisation (actual)"""

# https://pytorch.org/docs/stable/quantization.html
# uint_8 quantization or 16 bit

# torch.load(PSPNet_WOW_UPdated_A100_best_val)

# n_classes = len(get_disease_color_map())

# psp_model = pspnet(n_classes)

# state = torch.load(os.path.join("models_weights", '_'.join(["PSPNet_WOW_UPdated_A100","best_val"])),map_location=device)
# psp_model.load_state_dict(state)
# psp_model.eval()
# psp_model.to(device)

import torch
from torch.quantization import get_default_qconfig, quantize_jit
from tqdm import tqdm
import json

state = torch.load(os.path.join("models_weights", '_'.join(["PSPNet_WOW_UPdated_A100","best_val"])),map_location=device)
psp_model.load_state_dict(state)
psp_model.eval()
psp_model.to(device)
size = model_size_in_memory(psp_model)
print(f"Approximate actual model size in memory: {size} MB")

# Set the qconfig (Choose the appropriate qconfig for your use case)
qconfig = get_default_qconfig('qnnpack')  # 'fbgemm' for x86, 'qnnpack' for ARM
psp_model.qconfig = qconfig

fuse_list = [
    # Fusing in convbnrelu1_X submodules
    ['convbnrelu1_1.cbr_unit.0', 'convbnrelu1_1.cbr_unit.1'],
    ['convbnrelu1_2.cbr_unit.0', 'convbnrelu1_2.cbr_unit.1'],
    ['convbnrelu1_3.cbr_unit.0', 'convbnrelu1_3.cbr_unit.1'],

    # Fusing in residualBlockPSP submodules (example for res_block2)
    ['res_block2.layers.0.cbr1.cbr_unit.0', 'res_block2.layers.0.cbr1.cbr_unit.1'],
    ['res_block2.layers.0.cbr2.cbr_unit.0', 'res_block2.layers.0.cbr2.cbr_unit.1'],
    ['res_block2.layers.0.cb3.cb_unit.0', 'res_block2.layers.0.cb3.cb_unit.1'],
    # Repeat similar patterns for all layers in res_block2
    # Repeat for all other residual blocks (res_block3, res_block4, etc.)

    # Fusing in pyramidPooling module
    ['pyramid_pooling.path_module_list.0.cbr_unit.0', 'pyramid_pooling.path_module_list.0.cbr_unit.1'],
    # Repeat for other indices in path_module_list if applicable

    # Fusing in final layers
    ['cbr_final.cbr_unit.0', 'cbr_final.cbr_unit.1'],
    ['convbnrelu4_aux.cbr_unit.0', 'convbnrelu4_aux.cbr_unit.1'],
    # Any other similar sequences in your model
]

psp_model = torch.quantization.fuse_modules(psp_model,  fuse_list)

# Convert the model to a quantized version
psp_model_fp32_prepared = torch.quantization.prepare(psp_model, inplace=False)

# Testing with ground truth
test_json_path = 'reformatted_ChestX_Det_test.json'
with open(test_json_path,'r')as f:
    test_json =  json.load(f)

test_path = 'test_data'
test_dataset = ImageDataset(img_folder=test_path,transforms_=train_transforms,transforms_n = transform_n,image_size = 512,annotation_json = test_json,num_classes =13)
batch_size = 1
random_seed= 42
test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False)

for batch in test_dataloader:
    inputs = batch[0].to(device)
    psp_model_fp32_prepared(inputs)

# Convert to quantized model
psp_model_int8 = torch.quantization.convert(psp_model_fp32_prepared, inplace=False)

psp_model_int8

## Load test data
test_json_path = 'reformatted_ChestX_Det_test.json'
with open(test_json_path, 'r') as f:
    test_json = json.load(f)

test_path = 'test_data'
# Assuming ImageDataset and other necessary imports and functions are defined
test_dataset = ImageDataset(img_folder=test_path,transforms_=train_transforms,transforms_n = transform_n,image_size = 512,annotation_json = test_json,num_classes =13)
test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False)

# Testing loop
epoch_losses = {'vdice': list()}
test_bar = tqdm(test_dataloader)
seg_criterion = nn.BCEWithLogitsLoss()
psp_model_int8.eval()  # Use the quantized model
v_dice = []

with torch.no_grad():
    all_targets = []
    all_preds = []
    val_loss = 0
    for i, batch in enumerate(test_bar):
        test_bar.set_description("Validation")
        val_x, val_y = batch[0].to(device, dtype=torch.float), batch[1].to(device, dtype=torch.float)

        # Use the quantized model for prediction
        vout = psp_model_int8(val_x)

        vloss = seg_criterion(val_y, vout)
        all_targets.append(val_y)
        all_preds.append(vout)
        vdmean = DICE(val_y, vout, 1e-5)
        vloss = vloss.item() + 0.5 * (1 - vdmean).item()
        val_loss += vloss
        v_dice.append(vdmean.item())
        test_bar.set_postfix_str(f'loss: {val_loss/(i+1):.4f} dice: {vdmean.item():.4f}')
    all_targets = torch.cat(all_targets, axis=0)
    all_preds = torch.cat(all_preds, axis=0)

    vdmean = DICE(all_targets, all_preds, 1e-5)

    print(f'Test DICE : {vdmean.item():.4f}')
    epoch_losses['vdice'].append(vdmean.item())

def model_size_in_memory(model):
    param_size = 0
    for param in model.parameters():
        param_size += param.nelement() * param.element_size()
    buffer_size = 0
    for buffer in model.buffers():
        buffer_size += buffer.nelement() * buffer.element_size()
    total_size = param_size + buffer_size
    return total_size / (1024 * 1024)  # Convert to Megabytes

size = model_size_in_memory(psp_model)
print(f"Approximate actual model size in memory: {size} MB")

size = model_size_in_memory(psp_model_int8)
print(f"Approximate quantized model size in memory: {size} MB")

# torch.save(psp_model_int8.state_dict(), 'quantized_pspnet.pth')

print(psp_model_int8)

torch.save(psp_model_int8.state_dict(),os.path.join("models_weights", '_'.join(["PSPNet_WOW_UPdated_A100_quantised","best_val"])))

# # PSPNet to Quantisized model
# class QuantizablePSPNet(pspnet):
#     def __init__(self, *args, **kwargs):
#         super(QuantizablePSPNet, self).__init__(*args, **kwargs)
#         self.quant = torch.quantization.QuantStub()
#         self.dequant = torch.quantization.DeQuantStub()

#     def forward(self, x):
#         x = self.quant(x)
#         x = super(QuantizablePSPNet, self).forward(x)
#         x = self.dequant(x)
#         return x

# from pre_trained_PSPNet.ptsemseg.utils import conv2DBatchNormRelu

# def fuse_model(model):
#     for m in model.modules():
#         if type(m) == conv2DBatchNormRelu:
#           torch.ao.quantization.fuse_modules(m.cbr_unit, ['0', '1', '2'], inplace=True)

# model = QuantizablePSPNet(n_classes=18, version='pascal')
# model.eval()

# fuse_model(model)

# qconfig = torch.quantization.get_default_qconfig('qnnpack') # or 'qnnpack' for ARM CPUs
# model.qconfig = qconfig
# torch.quantization.prepare(model, inplace=True)

# torch.quantization.convert(model, inplace=True)



# import torch
# import torch.quantization
# import numpy as np
# import torch.nn as nn
# from math import ceil

# # ... [Your entire model code here] ...

# # Load pretrained weights if any or train your model
# # model = pspnet(version='pascal')
# # model.load_state_dict(torch.load('path_to_pspnet_weights.pth'))
# # model.eval()

# # 1. Fuse modules - this optimizes the model's size and speeds up its inference
# # Assuming utility functions like conv2DBatchNormRelu would have Conv, BN and ReLU layers

# # ... Repeat this for any other conv2DBatchNormRelu blocks ...

# # 2. Specify a quantization configuration and prepare the model
# qconfig = torch.quantization.get_default_qconfig('qnnpack') # or 'qnnpack' for ARM CPUs
# model.qconfig = qconfig
# torch.quantization.prepare(model, inplace=True)

# # 3. Calibrate the model
# # TODO: Run the model with some representative data here. This step is crucial.

# # 4. Convert the model to a quantized version
# torch.quantization.convert(model, inplace=True)

# # Now you can save the quantized model or use it for inference
# # torch.save(model.state_dict(), 'path_to_save_quantized_pspnet_weights.pth')

"""# Quantization 2"""

# param_size = 0
# for param in model.parameters():
#     param_size += param.nelement() * param.element_size()
# buffer_size = 0
# for buffer in model.buffers():
#     buffer_size += buffer.nelement() * buffer.element_size()

# size_all_mb = (param_size + buffer_size) / 1024**2
# print('model size: {:.3f}MB'.format(size_all_mb))

# torch.cuda.memory_summary(device)

"""# Test Accuracy

"""

def tensor_2_image(image):
    return image.numpy().transpose((1, 2, 0))

def imshow(image, ax=None, title=None, normalize=False):
    """Imshow for Tensor."""
    if ax is None:
        fig, ax = plt.subplots()

    if normalize:
        mean = np.array([0.485, 0.456, 0.406])
        std = np.array([0.229, 0.224, 0.225])
        image = std * image + mean
        image = np.clip(image, 0, 1)

    ax.imshow(image)
    ax.spines['top'].set_visible(False)
    ax.spines['right'].set_visible(False)
    ax.spines['left'].set_visible(False)
    ax.spines['bottom'].set_visible(False)
    ax.tick_params(axis='both', length=0)
    ax.set_xticklabels('')
    ax.set_yticklabels('')

    return ax
def draw_segment(tensor,poly,color= (255,0,0)):
    image = tensor_2_image(tensor)
    points = np.array([poly],dtype='int32')
    cv2.fillPoly(image,pts = points,color= color)
    return image

def get_mask(points):
    mask = np.full((1024,1024),False)
    if len(points) ==0:

        return mask
    for i, poly in enumerate(points):
        img = Image.new('L', (1024,1024), 0)
        poly = [(x,y) for x,y in poly]
        ImageDraw.Draw(img).polygon(poly, outline=1, fill=1)
        curr_mask = np.array(img)
        mask = np.dstack((mask,curr_mask))
    return mask[:,:,1:].transpose((2,0,1))
def generate_mask(data,jsonF):
    mask = []
    for d in data:
        polygons =  jsonF[d]["polygons"]
        mask.append(get_mask(polygons))
    return mask

test_img,test_data = next(iter(test_dataloader))

test_mask = generate_mask(test_data,test_json)

len(test_mask)

test_json[test_data[0]]

["Normal","Atelectasis", "Calcification", Cardiomegaly, Consolidation, Diffuse Nodule, Effusion, Emphysema, Fibrosis, Fracture, Mass, Nodule, Pleural Thickening, Pneumothorax]

import cv2
import numpy as np
import os
from tqdm import tqdm



# Function to create masks of different colors for each disease category
def create_colored_masks(image_shape, polygons, syms):
    #colors = [(255, 0, 0), (0, 255, 0), (0, 0, 255), (255, 255, 0), (255, 0, 255), (0, 255, 255),
              #(128, 0, 0), (0, 128, 0), (0, 0, 128), (128, 128, 0), (128, 0, 128), (0, 128, 128),
              #(255, 128, 0)]  # 13 distinct colors for 13 disease categories
    disease_color_map = {
    'Atelectasis': (1,(255, 0, 0)),         # Red
    'Calcification': (2,(0, 255, 0)),       # Green
    'Cardiomegaly': (3,(0, 0, 255)),        # Blue
    'Consolidation': (4,(255, 255, 0)),     # Yellow
    'Diffuse Nodule': (5,(255, 0, 255)),    # Magenta
    'Effusion': (6,(0, 255, 255)),          # Cyan
    'Emphysema': (7,(128, 0, 0)),           # Dark Red
    'Fibrosis': (8,(0, 128, 0)),            # Dark Green
    'Fracture': (9,(0, 0, 128)),            # Dark Blue
    'Mass': (10,(128, 128, 0)),              # Olive
    'Nodule': (11,(128, 0, 128)),            # Purple
    'Pleural Thickening': (12,(0, 128, 128)), # Teal
    'Pneumothorax': (13,(128, 128, 128))     # Gray
    }

    mask = np.full(image_shape,0)

    for idx, (polygon, sym) in enumerate(zip(polygons, syms)):
      ch = disease_color_map[sym][0] - 1
      mask[:,:,ch] = mask[:,:,ch] | get_mask(polygon)



    return mask

def get_mask(points):
    mask = np.full((1024,1024),False)
    if len(points) ==0:
        return mask
    img = Image.new('L', (1024,1024), 0)
    poly = [(x,y) for x,y in points]
    ImageDraw.Draw(img).polygon(poly, outline=1, fill=1)
    curr_mask = np.array(img)

    return curr_mask

train_json_path = 'ChestX_Det_train.json'
with open(train_json_path,'r')as f:
    annotations =  json.load(f)

train_json["45522.png"]

m = create_colored_masks((1024,1024,13),train_json["45522.png"]["polygons"],train_json["45522.png"]["syms"])

plt.imshow(m[:,:,11],cmap='gray')

train_json_path = 'ChestX_Det_train.json'
with open(train_json_path,'r')as f:
    annotations =  json.load(f)
# Generate and save colored masks
for idx, annotation in enumerate(tqdm(annotations)):
    image_shape = (1024, 1024,13)  # Replace with the actual shape of your images
    masks = create_colored_masks(image_shape, annotation['polygons'], annotation['syms'])

    # Save the mask as an image
    file_name = annotation['file_name']
    mask_filename = os.path.join('masks/train', f'{str(os.path.splitext(file_name)[0])}')

    np.save(mask_filename, masks)


print("All masks saved successfully.")

len(os.listdir("masks/train"))

